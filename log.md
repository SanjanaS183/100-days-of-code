# 100 Days Of Code - Log

Day 1 of #100DaysOfCode specifically #100DaysOfMLCode 

I started working on a kaggle titanic dataset which is building a model to decide whether a passenger will be saved.
Other than that, I also coded in python to implement dimensionality reduction.

Day 2:
Looked at different ML algorithms to decide which is best to implement for a specific problem.
Decided on Random Forest algo and started to code.

Day 3:
I had a data mining assignment where I coded in python. 
I had to visualise data through graphs. Used Seaborn library to visualise.

Day 4:
Wrote the Code for the  Kaggle titanic project completely from data processing to validation. 
This is my first time doing the full steps. 
Will improve it in the coming days and will try to get a good accuracy. 

Link: https://www.kaggle.com/code/sanjanasatish68l/titanic-first-project

Day 5:
Implemented the beta function in python using Scipy. Calculated cdf and pdf. 
Learned how code of integration works and used it to find probability 
using probability distribution function over certain limits. 

Day 6: 
Used KNN algorithm for developing a model for sklearn Iris dataset. 
Found the accuracy and obtain the confusion matrix. Went through code for Logistic regression. 

ay 7: 
Coded for getting convolution of two functions. 
Learned how to use enumerate and append in a for loop. 
Using a loop, added values to an empty list for certain calculations. 
Used pandas data reader, to get information. 

Day 8:
Wrote code for t distribution 
Found itâ€™s skew and kurtosis 
Coded from scratch a QQ plot to compare two t distributions. 

Day 9:
Developed a machine learning model to detect fake news using support vector machine algorithm. 
Preprocessing and feature extraction was done.
Trained the model and predicted labels
Obtained accuracy along with confusion matrix.

Day 10: 
Did some error analysis on the SVM model built yesterday. 
Printed out the true and predicted labels to analyse to a file for one fold of data.
Tried to improve accuracy by adding more preprocessing and features extraction steps. 

Day 11: 
Improved accuracy of model by pre-processing (removed stop-words, did stemming and lemmatisation). 
Changed parameters for svm classifier as well. 
Added new data as labels to get better accuracy.

Day 12:
For a machine learning model with support vector classifier. 
I was doing the optimisation to increase accuracy. 
Additional labels were added and extra preprocessing was done.  
Finally, tested the model in the test data. 

Day 13:
Wrote some code related to data warehousing. 
Mainly for cubes which is a python framework for OLAP. 
Wrote function to slice and dice cubes.

Day 14: 
Wrote code for models for a small dataset using svm and random forest algorithm. 
Tested parameter grid method to fit models having ideal parameters.
Explored frequent item sets.

Day 15: 
Read about the basic overview of deep learning. 
Explored deep learning methods to classify sound. 
I have a group of sounds from different parts of London. 
In the coming weeks I have classify it and should create a new problem statement. 
